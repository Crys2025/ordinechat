import os

# ğŸ”¥ È˜tergem proxy-urile Ã®nainte sÄƒ importÄƒm OpenAI (ca sÄƒ nu dea eroare pe server)
for key in ["HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY",
            "http_proxy", "https_proxy", "all_proxy"]:
    os.environ.pop(key, None)

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from qdrant_client import QdrantClient

from openai import OpenAI

# ğŸ”§ Config modele + colecÈ›ie
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
COLLECTION_NAME = os.getenv("COLLECTION_NAME", "ordine_site")

# ğŸ”‘ ClienÈ›i OpenAI + Qdrant
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

qdrant = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)

# ğŸš€ FastAPI app
app = FastAPI()

# CORS â€“ permite apeluri din WordPress / alt domeniu
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Servire fiÈ™iere statice (ordinebot.js etc.)
app.mount("/static", StaticFiles(directory="static"), name="static")


# ğŸ“© Schema request â€“ TRIMITEM ÃNTREAGA CONVERSAÈšIE
class Question(BaseModel):
    messages: list  # [{role: "user"/"assistant", content: "..."}, ...]


@app.get("/")
def home():
    return {"status": "ok", "message": "OrdineBot backend online"}


@app.post("/ask")
def ask(question: Question):
    """
    Endpoint-ul principal.
    PrimeÈ™te toatÄƒ conversaÈ›ia (messages) È™i foloseÈ™te:
    - ultimul mesaj de la user pentru cÄƒutarea Ã®n Qdrant
    - toatÄƒ conversaÈ›ia ca memorie pentru model
    """

    # ğŸ§  Memorie conversaÈ›ionalÄƒ â€“ extragem ultimul mesaj de la user
    conversation_history = question.messages
    last_user_messages = [m for m in conversation_history if m.get("role") == "user"]

    if not last_user_messages:
        return {"answer": "Nu existÄƒ un mesaj de utilizator Ã®n conversaÈ›ie."}

    current_query = last_user_messages[-1]["content"]

    # ğŸ“Œ Embedding pe ÃNTREBAREA CURENTÄ‚
    emb = client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=current_query,
    )
    vector = emb.data[0].embedding

    # ğŸ” CÄƒutare Ã®n Qdrant
    hits = qdrant.search(
        collection_name=COLLECTION_NAME,
        query_vector=vector,
        limit=5,
    )

    # â— DacÄƒ nu gÄƒsim nimic Ã®n Qdrant â†’ rÄƒspundem explicit
    if not hits:
        return {"answer": "Nu existÄƒ informaÈ›ii despre asta pe site."}

    # ğŸ§± Construim contextul din articole
    context = ""
    for h in hits:
        payload = h.payload or {}
        context += (
            f"Titlu: {payload.get('title')}\n"
            f"URL: {payload.get('url')}\n"
            f"Text: {payload.get('text')}\n\n---\n\n"
        )

    # ğŸ§  Prompt de sistem â€“ OrdineBot + memorie conversaÈ›ionalÄƒ
    system = (
        "EÈ™ti OrdineBot, un asistent care rÄƒspunde STRICT pe baza articolelor "
        "de pe site-ul ordinesaudezordine.com/. "
        "Ai memorie conversaÈ›ionalÄƒ: foloseÈ™ti Ã®ntrebÄƒrile È™i rÄƒspunsurile anterioare "
        "ca sÄƒ deduci la ce se referÄƒ utilizatorul cÃ¢nd spune, de exemplu, "
        "'dÄƒ-mi linkul' sau 'aratÄƒ-mi articolul'. "
        "Nu inventezi informaÈ›ii. Nu adaugi opinii personale. "
        "RÄƒspunzi foarte concis, 1-3 fraze maxim. "
        "DACÄ‚ Ã®ntrebarea nu are rÄƒspuns Ã®n context, spui exact: "
        "'Nu existÄƒ informaÈ›ii despre asta pe site.' "
        "Nu foloseÈ™ti generalitÄƒÈ›i, nu deviezi de la context."
    )

    # ğŸ§  Trimitem cÄƒtre model:
    # - instrucÈ›iunile (system)
    # - contextul din articole (alt system)
    # - toatÄƒ conversaÈ›ia user â†” bot
    messages = [
        {"role": "system", "content": system},
        {"role": "system", "content": f"Context din articolele de pe site:\n{context}"},
    ] + conversation_history

    resp = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=messages,
    )

    return {"answer": resp.choices[0].message.content}
